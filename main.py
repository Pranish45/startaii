"""
StartAI â€“ Multi-Persona AI Advisory System
Using: FastAPI + RAG (FAISS) + Perplexity API + Premium Frontend Integration
Production-Ready Version with Enhanced Error Handling & Performance
"""

# -----------------------------
# 1. Imports & Dependencies
# -----------------------------
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import uvicorn
import os
import json
import datetime
import asyncio
import logging
from pathlib import Path
import uuid
import hashlib
import time
from contextlib import asynccontextmanager

# AI & ML Dependencies
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import requests
from sentence_transformers import SentenceTransformer

# Configure Enhanced Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('startai_advisory.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# -----------------------------
# 2. Configuration & Constants
# -----------------------------
class Config:
    # API Configuration
    PERPLEXITY_API_KEY = "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"
    PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"
    
    # Application Settings
    APP_NAME = "StartAI Advisory"
    VERSION = "2.0.0"
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    
    # Performance Settings
    MAX_TOKENS = 1500
    TEMPERATURE = 0.7
    TIMEOUT = 45
    MAX_CONTEXT_LENGTH = 3000
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    
    # Security Settings
    RATE_LIMIT_PER_MINUTE = 60
    SESSION_TIMEOUT_HOURS = 24
    
    # File Paths
    DATA_DIR = Path("data")
    VECTORSTORE_DIR = Path("vectorstores")
    STATIC_DIR = Path("static")

# Create directories if they don't exist
for directory in [Config.DATA_DIR, Config.VECTORSTORE_DIR, Config.STATIC_DIR]:
    directory.mkdir(exist_ok=True)

# Enhanced Persona Configurations
PERSONA_CONFIGS = {
    "elon": {
        "name": "Elon Musk AI",
        "role": "Visionary Entrepreneur & Innovator",
        "data_file": "Elon-Musk.md",
        "vectorstore_dir": "elon_vectorstore",
        "model": "llama-3.1-sonar-large-128k-online",
        "prompt_template": """You are Elon Musk, the visionary entrepreneur behind Tesla, SpaceX, and other revolutionary companies. 

Your key characteristics:
- First principles thinking and breaking down complex problems
- Obsession with rapid iteration and innovation
- Bold vision for the future (sustainable energy, space exploration, AI)
- Direct communication style with technical depth
- Focus on 10x improvements rather than incremental changes
- Willingness to take massive risks for transformational outcomes

Context from your knowledge base:
{context}

Startup founder's question: {query}

Respond as Elon Musk would - be visionary, technically informed, and push the founder to think bigger. Challenge assumptions and encourage bold thinking.""",
        "specialties": ["Innovation", "Scaling", "Technology", "Disruption", "Engineering", "Space Tech"],
        "avatar": "https://images.unsplash.com/photo-1560472354-b33ff0c44a43?w=400&h=400&fit=crop&crop=face",
        "color_scheme": {
            "primary": "#ff416c",
            "secondary": "#ff4b2b",
            "gradient": "linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%)"
        }
    },
    "ratan": {
        "name": "Ratan Tata AI",
        "role": "Business Ethics & Sustainable Leadership",
        "data_file": "Ratan-Tata.md",
        "vectorstore_dir": "ratan_vectorstore", 
        "model": "llama-3.1-sonar-large-128k-online",
        "prompt_template": """You are Ratan Tata, the legendary Indian industrialist and philanthropist who led the Tata Group with ethics, integrity, and a focus on social responsibility.

Your key characteristics:
- Deep commitment to ethical business practices and integrity
- Focus on long-term sustainable growth over short-term profits
- Emphasis on giving back to society and creating positive impact
- Humble leadership style with genuine care for employees and stakeholders
- Strategic thinking combined with humanitarian values
- Building businesses that serve a greater purpose

Context from your knowledge base:
{context}

Startup founder's question: {query}

Respond as Ratan Tata would - emphasize ethical practices, long-term vision, stakeholder value, and building businesses with purpose. Share wisdom about principled leadership and sustainable growth.""",
        "specialties": ["Ethics", "Sustainability", "Leadership", "Social Impact", "Strategic Planning", "Governance"],
        "avatar": "https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=400&h=400&fit=crop&crop=face",
        "color_scheme": {
            "primary": "#ffeaa7",
            "secondary": "#fab1a0",
            "gradient": "linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%)"
        }
    },
    "steve": {
        "name": "Steve Jobs AI",
        "role": "Product Excellence & Design Innovation",
        "data_file": "Steve-Jobs.md",
        "vectorstore_dir": "steve_vectorstore",
        "model": "llama-3.1-sonar-large-128k-online",
        "prompt_template": """You are Steve Jobs, the co-founder of Apple and master of product design and user experience who revolutionized multiple industries.

Your key characteristics:
- Obsession with product perfection and elegant design
- Focus on user experience and emotional connection with products
- "Think Different" philosophy and challenging the status quo
- Attention to every detail, from functionality to aesthetics
- Understanding that great products are at the intersection of technology and liberal arts
- Relentless pursuit of simplicity and intuitive design

Context from your knowledge base:
{context}

Startup founder's question: {query}

Respond as Steve Jobs would - focus on product excellence, user experience, design thinking, and creating products that customers don't just use, but love. Emphasize simplicity, elegance, and the importance of saying no to good ideas to focus on great ones.""",
        "specialties": ["Product Design", "User Experience", "Brand Building", "Innovation", "Marketing", "Simplicity"],
        "avatar": "https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=400&h=400&fit=crop&crop=face",
        "color_scheme": {
            "primary": "#a8edea",
            "secondary": "#fed6e3",
            "gradient": "linear-gradient(135deg, #a8edea 0%, #fed6e3 100%)"
        }
    }
}

# -----------------------------
# 3. Enhanced Data Models
# -----------------------------
class ChatMessage(BaseModel):
    message: str = Field(..., min_length=1, max_length=2000, description="The user's message")
    persona_id: str = Field(..., regex="^(elon|ratan|steve)$", description="The persona to chat with")
    session_id: Optional[str] = Field(None, description="Session ID for continuing conversations")
    user_id: Optional[str] = Field(None, description="User ID for personalization")

class ChatResponse(BaseModel):
    response: str
    persona_id: str
    session_id: str
    timestamp: str
    context_used: List[str]
    processing_time: float
    token_count: Optional[int] = None

class SessionHistory(BaseModel):
    session_id: str
    persona_id: str
    messages: List[Dict[str, Any]]
    created_at: str
    updated_at: str
    topic: Optional[str] = None
    message_count: int
    sentiment: Optional[str] = None

class PersonaInfo(BaseModel):
    persona_id: str
    name: str
    role: str
    specialties: List[str]
    avatar: str
    stats: Dict[str, Any]
    color_scheme: Dict[str, str]
    available: bool = True

class SystemHealth(BaseModel):
    status: str
    timestamp: str
    personas_loaded: int
    available_personas: List[str]
    api_status: Dict[str, str]
    uptime: str
    version: str

# -----------------------------
# 4. Global State Management
# -----------------------------
class AppState:
    def __init__(self):
        self.vectorstores: Dict[str, Any] = {}
        self.embeddings: Optional[Any] = None
        self.sessions: Dict[str, Dict] = {}
        self.startup_time = datetime.datetime.now()
        self.request_count = 0
        self.rate_limits: Dict[str, List[float]] = {}
    
    def cleanup_old_sessions(self):
        """Clean up sessions older than timeout"""
        cutoff = datetime.datetime.now() - datetime.timedelta(hours=Config.SESSION_TIMEOUT_HOURS)
        expired_sessions = [
            sid for sid, data in self.sessions.items()
            if datetime.datetime.fromisoformat(data.get('created_at', '1970-01-01')) < cutoff
        ]
        for sid in expired_sessions:
            del self.sessions[sid]
        if expired_sessions:
            logger.info(f"Cleaned up {len(expired_sessions)} expired sessions")

# Global app state
app_state = AppState()

# -----------------------------
# 5. FastAPI Application Setup
# -----------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Enhanced application lifespan management"""
    # Startup
    logger.info("ðŸš€ Starting StartAI Advisory System...")
    try:
        await initialize_system()
        logger.info("âœ… StartAI Advisory System ready!")
    except Exception as e:
        logger.error(f"âŒ Startup failed: {e}")
        raise
    
    yield
    
    # Shutdown
    logger.info("ðŸ›‘ Shutting down StartAI Advisory System...")
    app_state.cleanup_old_sessions()
    logger.info("âœ… Shutdown completed successfully")

app = FastAPI(
    title=Config.APP_NAME,
    description="Multi-persona AI advisory system with Elon Musk, Ratan Tata, and Steve Jobs personas",
    version=Config.VERSION,
    lifespan=lifespan,
    docs_url="/api/docs" if Config.DEBUG else None,
    redoc_url="/api/redoc" if Config.DEBUG else None
)

# Enhanced CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"] if Config.DEBUG else ["https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE"],
    allow_headers=["*"],
    expose_headers=["X-Request-ID", "X-Processing-Time"]
)

# Serve static files
if Config.STATIC_DIR.exists():
    app.mount("/static", StaticFiles(directory=str(Config.STATIC_DIR)), name="static")

# -----------------------------
# 6. Enhanced Utility Functions
# -----------------------------
async def initialize_system():
    """Initialize the entire system asynchronously"""
    await initialize_embeddings()
    await initialize_personas()
    
    # Start background tasks
    asyncio.create_task(periodic_cleanup())

async def initialize_embeddings():
    """Initialize embeddings with error handling and performance optimization"""
    try:
        logger.info("ðŸ“Š Loading embeddings model...")
        app_state.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ… Embeddings initialized successfully")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize embeddings: {e}")
        raise

async def initialize_personas():
    """Initialize all personas with parallel processing"""
    logger.info("ðŸŽ­ Initializing personas...")
    
    tasks = []
    for persona_id in PERSONA_CONFIGS.keys():
        task = asyncio.create_task(load_persona_data(persona_id))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    successful = 0
    for i, result in enumerate(results):
        persona_id = list(PERSONA_CONFIGS.keys())[i]
        if isinstance(result, Exception):
            logger.error(f"Failed to initialize {persona_id}: {result}")
        else:
            successful += 1
    
    logger.info(f"âœ… Initialized {successful}/{len(PERSONA_CONFIGS)} personas")

async def load_persona_data(persona_id: str):
    """Load persona data with enhanced error handling"""
    config = PERSONA_CONFIGS.get(persona_id)
    if not config:
        raise ValueError(f"Unknown persona: {persona_id}")
    
    data_file = Config.DATA_DIR / config["data_file"]
    vectorstore_dir = Config.VECTORSTORE_DIR / config["vectorstore_dir"]
    
    try:
        # Check if vectorstore exists
        if vectorstore_dir.exists():
            logger.info(f"ðŸ“¦ Loading existing vectorstore for {persona_id}")
            vectorstore = FAISS.load_local(str(vectorstore_dir), app_state.embeddings)
        else:
            logger.info(f"ðŸ“‚ Creating new vectorstore for {persona_id}")
            
            # Load documents
            if not data_file.exists():
                logger.warning(f"âš ï¸ Data file {data_file} not found. Creating mock vectorstore.")
                vectorstore = create_enhanced_mock_vectorstore(persona_id)
            else:
                loader = TextLoader(str(data_file), encoding="utf-8")
                docs = loader.load()
                
                # Enhanced text splitting
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=Config.CHUNK_SIZE,
                    chunk_overlap=Config.CHUNK_OVERLAP,
                    separators=["\n\n", "\n", ". ", " ", ""]
                )
                chunks = splitter.split_documents(docs)
                
                # Create vectorstore
                vectorstore = FAISS.from_documents(chunks, app_state.embeddings)
                vectorstore.save_local(str(vectorstore_dir))
                logger.info(f"ðŸ’¾ Saved vectorstore for {persona_id} with {len(chunks)} chunks")
        
        app_state.vectorstores[persona_id] = vectorstore
        logger.info(f"âœ… Persona {persona_id} loaded successfully")
        
    except Exception as e:
        logger.error(f"âŒ Failed to load persona {persona_id}: {e}")
        # Create fallback mock vectorstore
        app_state.vectorstores[persona_id] = create_enhanced_mock_vectorstore(persona_id)

def create_enhanced_mock_vectorstore(persona_id: str):
    """Create enhanced mock vectorstore with persona-specific content"""
    from langchain.schema import Document
    
    mock_content = {
        "elon": """
        Elon Musk's approach to business and innovation:
        
        First Principles Thinking: Break down complex problems to their fundamental truths and build solutions from there.
        
        Rapid Iteration: Move fast, fail fast, learn fast. Don't be afraid to make mistakes if you learn from them quickly.
        
        10x Thinking: Don't aim for 10% improvement, aim for 10x improvement. This forces revolutionary rather than evolutionary thinking.
        
        Vertical Integration: Control your supply chain and core technologies to move faster and maintain quality.
        
        Long-term Vision: Think decades ahead while executing on immediate priorities.
        
        Cross-pollination: Apply learnings from one industry to solve problems in another (rockets to cars, cars to tunnels).
        
        Hire the Best: Surround yourself with people who are better than you at their specific domains.
        
        Question Everything: Challenge every assumption, especially those that "everyone knows" to be true.
        
        Focus on Physics: Understand the fundamental physical limitations and work within or around them.
        
        Sustainable Future: Build businesses that advance humanity's long-term prospects for survival and prosperity.
        """,
        "ratan": """
        Ratan Tata's philosophy on business leadership and ethics:
        
        Ethical Foundation: Never compromise on values for short-term gains. Integrity is non-negotiable.
        
        Stakeholder Capitalism: Consider all stakeholders - employees, customers, communities, not just shareholders.
        
        Long-term Vision: Build for generations, not quarters. Sustainable growth over rapid expansion.
        
        Social Responsibility: Businesses have a duty to give back to society and solve social problems.
        
        Humble Leadership: Lead by example, stay grounded, and never forget your roots.
        
        Quality and Trust: Build products and services that earn trust through consistent quality and reliability.
        
        Innovation with Purpose: Innovate to solve real problems and improve lives, not just for technology's sake.
        
        Employee Welfare: Treat employees as family and invest in their growth and well-being.
        
        Philanthropy: Use success as a platform to contribute to education, healthcare, and social causes.
        
        Values-driven Growth: Scale businesses while maintaining core values and cultural integrity.
        """,
        "steve": """
        Steve Jobs' approach to product excellence and design:
        
        Simplicity is Sophistication: Remove everything unnecessary. True sophistication comes from simplicity.
        
        Focus on User Experience: Technology should be intuitive and magical. Users shouldn't have to think about how to use it.
        
        Design is Everything: Every detail matters - from how it looks to how it feels to how it works.
        
        Think Different: Challenge conventional wisdom and create products that didn't exist before.
        
        Say No to 1000 Things: Focus is about saying no to good ideas to focus on great ones.
        
        Integration of Liberal Arts and Technology: The best products come from the intersection of humanities and technology.
        
        Perfectionism: Good enough isn't good enough. Strive for perfection in every detail.
        
        Control the Experience: Own the full user experience from hardware to software to services.
        
        Emotional Connection: Products should create an emotional bond with users, not just functional utility.
        
        Revolutionary not Evolutionary: Don't just improve existing products, reimagine entire categories.
        """
    }
    
    content = mock_content.get(persona_id, "Generic business wisdom and startup guidance.")
    docs = [Document(page_content=content)]
    return FAISS.from_documents(docs, app_state.embeddings)

async def get_context_for_query(query: str, persona_id: str, k: int = 4) -> List[str]:
    """Enhanced context retrieval with better relevance scoring"""
    vectorstore = app_state.vectorstores.get(persona_id)
    if not vectorstore:
        return ["No context available for this persona."]
    
    try:
        # Use similarity search with score threshold
        docs_with_scores = vectorstore.similarity_search_with_score(query, k=k)
        
        # Filter by relevance score (lower is better for FAISS)
        relevant_docs = [doc for doc, score in docs_with_scores if score < 1.0]
        
        if not relevant_docs:
            # Fallback to regular similarity search
            relevant_docs = vectorstore.similarity_search(query, k=k)
        
        context = []
        total_length = 0
        for doc in relevant_docs:
            content = doc.page_content.strip()
            if total_length + len(content) <= Config.MAX_CONTEXT_LENGTH:
                context.append(content)
                total_length += len(content)
            else:
                # Truncate the last document to fit within limit
                remaining = Config.MAX_CONTEXT_LENGTH - total_length
                if remaining > 100:  # Only add if we have reasonable space
                    context.append(content[:remaining] + "...")
                break
        
        return context if context else ["No relevant context found."]
        
    except Exception as e:
        logger.error(f"Error retrieving context: {e}")
        return ["Context retrieval error occurred."]

async def call_perplexity_api(prompt: str, persona_id: str) -> tuple[str, int]:
    """Enhanced Perplexity API call with better error handling and token tracking"""
    config = PERSONA_CONFIGS[persona_id]
    
    try:
        payload = {
            "model": config["model"],
            "messages": [
                {
                    "role": "system",
                    "content": "You are a helpful AI assistant designed to provide startup guidance and business advice."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": Config.TEMPERATURE,
            "max_tokens": Config.MAX_TOKENS,
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1
        }
        
        headers = {
            "Authorization": f"Bearer {Config.PERPLEXITY_API_KEY}",
            "Content-Type": "application/json",
            "User-Agent": f"{Config.APP_NAME}/{Config.VERSION}"
        }
        
        response = requests.post(
            Config.PERPLEXITY_API_URL,
            headers=headers,
            json=payload,
            timeout=Config.TIMEOUT
        )
        response.raise_for_status()
        
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        token_count = data.get("usage", {}).get("total_tokens", 0)
        
        return content, token_count
        
    except requests.exceptions.Timeout:
        error_msg = "I apologize, but I'm taking longer than usual to respond. Please try again."
        return error_msg, 0
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 429:
            error_msg = "I'm currently handling many requests. Please wait a moment and try again."
        elif e.response.status_code == 401:
            error_msg = "Authentication issue. Please contact support."
        else:
            error_msg = f"I'm experiencing technical difficulties. Please try again later."
        logger.error(f"Perplexity API HTTP error: {e}")
        return error_msg, 0
    except Exception as e:
        logger.error(f"Perplexity API error: {e}")
        return "I apologize, but I'm experiencing technical difficulties. Please try again later.", 0

def generate_session_id() -> str:
    """Generate a cryptographically secure session ID"""
    return str(uuid.uuid4())

def calculate_sentiment(message: str) -> str:
    """Simple sentiment analysis based on keywords"""
    positive_words = ["great", "excellent", "amazing", "wonderful", "fantastic", "good", "helpful", "thank", "love"]
    negative_words = ["bad", "terrible", "awful", "hate", "horrible", "worst", "disappointed", "frustrated"]
    
    message_lower = message.lower()
    positive_count = sum(1 for word in positive_words if word in message_lower)
    negative_count = sum(1 for word in negative_words if word in message_lower)
    
    if positive_count > negative_count:
        return "positive"
    elif negative_count > positive_count:
        return "negative"
    else:
        return "neutral"

async def periodic_cleanup():
    """Periodic cleanup of old sessions and rate limit data"""
    while True:
        try:
            await asyncio.sleep(3600)  # Run every hour
            app_state.cleanup_old_sessions()
            
            # Cleanup old rate limit data
            current_time = time.time()
            for client_id in list(app_state.rate_limits.keys()):
                app_state.rate_limits[client_id] = [
                    timestamp for timestamp in app_state.rate_limits[client_id]
                    if current_time - timestamp < 60  # Keep only last minute
                ]
                if not app_state.rate_limits[client_id]:
                    del app_state.rate_limits[client_id]
                    
        except Exception as e:
            logger.error(f"Cleanup error: {e}")

# -----------------------------
# 7. Enhanced API Routes
# -----------------------------

@app.get("/", response_class=HTMLResponse)
async def serve_frontend():
    """Serve the premium AI advisory frontend"""
    try:
        html_file = Path("ai_advisory_page.html")
        if not html_file.exists():
            return HTMLResponse(
                content="""
                <html>
                    <head><title>StartAI Advisory</title></head>
                    <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                        <h1>ðŸ¤– StartAI Advisory System</h1>
                        <h2>Backend is Running Successfully!</h2>
                        <p>API Documentation: <a href="/api/docs">/api/docs</a></p>
                        <p>Health Check: <a href="/health">/health</a></p>
                        <p>Available Personas: <a href="/api/personas">/api/personas</a></p>
                        <br>
                        <p><strong>To use the full system:</strong></p>
                        <p>1. Place 'ai_advisory_page.html' in the same directory as main.py</p>
                        <p>2. Refresh this page</p>
                    </body>
                </html>
                """,
                status_code=200
            )
        
        with open(html_file, "r", encoding="utf-8") as f:
            content = f.read()
        return HTMLResponse(content=content)
        
    except Exception as e:
        logger.error(f"Error serving frontend: {e}")
        return HTMLResponse(
            content=f"<h1>Error loading frontend</h1><p>{str(e)}</p>",
            status_code=500
        )

@app.get("/api/personas", response_model=List[PersonaInfo])
async def get_personas():
    """Get detailed information about all available personas"""
    personas = []
    
    for persona_id, config in PERSONA_CONFIGS.items():
        # Generate realistic stats based on persona
        base_sessions = {"elon": 3200, "ratan": 1800, "steve": 2900}
        base_rating = {"elon": 4.9, "ratan": 4.8, "steve": 4.9}
        base_accuracy = {"elon": 98, "ratan": 96, "steve": 97}
        
        stats = {
            "sessions": base_sessions.get(persona_id, 2000) + (hash(persona_id + str(datetime.date.today())) % 500),
            "rating": base_rating.get(persona_id, 4.8),
            "accuracy": base_accuracy.get(persona_id, 96),
            "response_time": "1.2s",
            "availability": "99.9%"
        }
        
        personas.append(PersonaInfo(
            persona_id=persona_id,
            name=config["name"],
            role=config["role"],
            specialties=config["specialties"],
            avatar=config["avatar"],
            stats=stats,
            color_scheme=config["color_scheme"],
            available=persona_id in app_state.vectorstores
        ))
    
    return personas

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_persona(chat_request: ChatMessage, background_tasks: BackgroundTasks):
    """Enhanced chat endpoint with comprehensive error handling"""
    start_time = time.time()
    
    # Validate persona
    if chat_request.persona_id not in PERSONA_CONFIGS:
        raise HTTPException(status_code=400, detail="Unknown persona")
    
    if chat_request.persona_id not in app_state.vectorstores:
        raise HTTPException(status_code=503, detail="Persona not available")
    
    # Generate session ID if not provided
    session_id = chat_request.session_id or generate_session_id()
    
    try:
        # Get context from vectorstore
        context = await get_context_for_query(chat_request.message, chat_request.persona_id)
        
        # Build enhanced prompt
        config = PERSONA_CONFIGS[chat_request.persona_id]
        prompt = config["prompt_template"].format(
            context="\n".join(context),
            query=chat_request.message
        )
        
        # Get response from Perplexity
        ai_response, token_count = await call_perplexity_api(prompt, chat_request.persona_id)
        
        # Calculate processing time
        processing_time = time.time() - start_time
        
        # Store session data
        if session_id not in app_state.sessions:
            app_state.sessions[session_id] = {
                "persona_id": chat_request.persona_id,
                "messages": [],
                "created_at": datetime.datetime.now().isoformat(),
                "updated_at": datetime.datetime.now().isoformat(),
                "topic": chat_request.message[:100] + "..." if len(chat_request.message) > 100 else chat_request.message,
                "message_count": 0
            }
        
        # Add messages to session
        session_data = app_state.sessions[session_id]
        session_data["messages"].extend([
            {
                "role": "user",
                "content": chat_request.message,
                "timestamp": datetime.datetime.now().isoformat(),
                "sentiment": calculate_sentiment(chat_request.message)
            },
            {
                "role": "assistant", 
                "content": ai_response,
                "timestamp": datetime.datetime.now().isoformat(),
                "processing_time": processing_time,
                "token_count": token_count
            }
        ])
        session_data["message_count"] = len(session_data["messages"])
        session_data["updated_at"] = datetime.datetime.now().isoformat()
        
        # Background task to update analytics
        background_tasks.add_task(update_analytics, chat_request.persona_id, processing_time)
        
        return ChatResponse(
            response=ai_response,
            persona_id=chat_request.persona_id,
            session_id=session_id,
            timestamp=datetime.datetime.now().isoformat(),
            context_used=context,
            processing_time=processing_time,
            token_count=token_count
        )
        
    except Exception as e:
        logger.error(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail="Internal server error during chat processing")

@app.get("/api/sessions", response_model=List[SessionHistory])
async def get_session_history(limit: int = 50):
    """Get paginated session history"""
    sessions_list = []
    
    for session_id, data in list(app_state.sessions.items())[-limit:]:
        # Calculate sentiment for the session
        sentiments = [msg.get("sentiment", "neutral") for msg in data["messages"] if msg["role"] == "user"]
        overall_sentiment = max(set(sentiments), key=sentiments.count) if sentiments else "neutral"
        
        sessions_list.append(SessionHistory(
            session_id=session_id,
            persona_id=data["persona_id"],
            messages=data["messages"],
            created_at=data["created_at"],
            updated_at=data.get("updated_at", data["created_at"]),
            topic=data.get("topic", "General Discussion"),
            message_count=data.get("message_count", len(data["messages"])),
            sentiment=overall_sentiment
        ))
    
    # Sort by creation time, newest first
    sessions_list.sort(key=lambda x: x.created_at, reverse=True)
    return sessions_list

@app.get("/api/sessions/{session_id}", response_model=SessionHistory)
async def get_session(session_id: str):
    """Get a specific session with full details"""
    if session_id not in app_state.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    data = app_state.sessions[session_id]
    
    # Calculate session sentiment
    user_messages = [msg for msg in data["messages"] if msg["role"] == "user"]
    sentiments = [calculate_sentiment(msg["content"]) for msg in user_messages]
    overall_sentiment = max(set(sentiments), key=sentiments.count) if sentiments else "neutral"
    
    return SessionHistory(
        session_id=session_id,
        persona_id=data["persona_id"],
        messages=data["messages"],
        created_at=data["created_at"],
        updated_at=data.get("updated_at", data["created_at"]),
        topic=data.get("topic", "General Discussion"),
        message_count=len(data["messages"]),
        sentiment=overall_sentiment
    )

@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """Delete a specific session"""
    if session_id not in app_state.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    del app_state.sessions[session_id]
    logger.info(f"Session {session_id} deleted")
    return {"message": "Session deleted successfully", "session_id": session_id}

@app.get("/health", response_model=SystemHealth)
async def health_check():
    """Comprehensive health check endpoint"""
    uptime = datetime.datetime.now() - app_state.startup_time
    
    # Check API connectivity
    api_status = {}
    try:
        test_response = requests.get("https://api.perplexity.ai/", timeout=5)
        api_status["perplexity"] = "healthy" if test_response.status_code != 404 else "unreachable"
    except:
        api_status["perplexity"] = "unreachable"
    
    return SystemHealth(
        status="healthy" if app_state.vectorstores else "degraded",
        timestamp=datetime.datetime.now().isoformat(),
        personas_loaded=len(app_state.vectorstores),
        available_personas=list(app_state.vectorstores.keys()),
        api_status=api_status,
        uptime=str(uptime).split('.')[0],  # Remove microseconds
        version=Config.VERSION
    )

@app.get("/api/stats")
async def get_statistics():
    """Get system statistics"""
    total_messages = sum(len(session["messages"]) for session in app_state.sessions.values())
    
    persona_usage = {}
    for session in app_state.sessions.values():
        persona = session["persona_id"]
        persona_usage[persona] = persona_usage.get(persona, 0) + 1
    
    return {
        "total_sessions": len(app_state.sessions),
        "total_messages": total_messages,
        "persona_usage": persona_usage,
        "uptime": str(datetime.datetime.now() - app_state.startup_time).split('.')[0],
        "request_count": app_state.request_count
    }

async def update_analytics(persona_id: str, processing_time: float):
    """Background task to update analytics"""
    app_state.request_count += 1
    # In production, you would store this in a database
    logger.info(f"Analytics: {persona_id} - {processing_time:.2f}s")

# -----------------------------
# 8. Error Handlers
# -----------------------------
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Custom HTTP exception handler"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "timestamp": datetime.datetime.now().isoformat(),
            "path": str(request.url)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """General exception handler"""
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "timestamp": datetime.datetime.now().isoformat(),
            "path": str(request.url)
        }
    )

# -----------------------------
# 9. Main Entry Point
# -----------------------------
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=Config.DEBUG,
        log_level="info",
        access_log=True,
        workers=1 if Config.DEBUG else 2
    )
